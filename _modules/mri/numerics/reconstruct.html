<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
  
    <title>MRI &mdash; pysap-mri</title>
  <!-- htmltitle is before nature.css - we use this hack to load bootstrap first -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="stylesheet" href="../../../_static/css/bootstrap.min.css" media="screen" />

    
    <link rel="stylesheet" href="../../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/gallery.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     '0.1.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <link rel="top" title="pysap-mri" href="../../../index.html" />
    <link rel="up" title="Module code" href="../../index.html" />
  
   
       <script type="text/javascript" src="../../../_static/sidebar.js"></script>
   
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <script src="../../../_static/js/bootstrap.min.js" type="text/javascript"></script>

  <script src="../../../_static/js/angular.min.js" type="text/javascript"></script>
  <script type="text/javascript">
    var app = angular.module("navApp", []);
    app.controller('navCtrl', ['$scope', '$window', function($scope, $window) {
      $scope.isActive = function (viewLocation) {
        var rel = $window.location.pathname.split("/")
        rel = rel[rel.length - 1]
        rel = rel.split(".")[0]
        var active = (viewLocation === rel);
        return active;};
    }]);
  </script>

  </head>
  <body role="document"><div class="banner">
  <div class="container-fluid banner-container">
    <div class="row banner-inner">
      <div class="col-xs-4">
        <img alt="Logo" src="../../../_static/mri.png">
      </div>
      <div class="col-xs-8">
            <p>Python Sparse data Analysis Package external MRI plugin.</p>
      </div>
    </div>  
  </div>
</div><nav class="navbar navbar-default navbar-static-top">
  <div class="container-fluid">
    <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../../index.html">
        </a>
    </div>
    <div id="navbar" class="navbar-collapse collapse" ng-controller="navCtrl" ng-app="navApp">
      <ul class="nav navbar-nav">
        <li ng-class="{ active: isActive('index') }"><a href="../../../index.html">Home</a></li>
        <li ng-class="{ active: isActive('installation') }"><a href="../../../generated/installation.html">Installation</a></li>
        <li ng-class="{ active: isActive('gallery') }"><a href="../../../auto_gallery/gallery.html">Gallery</a></li>
        <li ng-class="{ active: isActive('documentation') }"><a href="../../../generated/documentation.html">API documentation</a></li>
        <!--<li class="dropdown">
          <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false"> <span class="caret"></span></a>
          <ul class="dropdown-menu">
	        <li><a href="../../../generated/mri.html">Mri</a></li>
<li><a href="../../../generated/mri.dictionary_learning.html">Mri.dictionary learning</a></li>
<li><a href="../../../generated/mri.parallel_mri.html">Mri.parallel mri</a></li>
<li><a href="../../../generated/mri.numerics.html">Mri.numerics</a></li>
<li><a href="../../../generated/mri.reconstruct.html">Mri.reconstruct</a></li>
          </ul>
        </li>-->
        <li><a href="http://cosmic.cosmostat.org/">COSMIC webPage</a></li>
      </ul>
    </div>
  </div>
</nav>
<div class="content-wrapper">
    <div class="sphinxsidebar">
      <div class="sphinxsidebarwrapper">

        <!-- info setup -->
          <p class="doc-version">
           This documentation is for mri <strong>version 0.1.1</strong>
          </p>
        <p class="citing">
          If you use the software, please do not hesitate to 
          <a &mdash; <a href="https://github.com/CEA-COSMIC/pysap-mri">
          Report a Bug</a>.
        </p>

      <!-- toc tree -->
      

      </div>
    </div>
  

  <div class="content">
      
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for mri.numerics.reconstruct</h1><div class="highlight"><pre>
<span class="c1"># -*- coding: utf-8 -*-</span>
<span class="c1">##########################################################################</span>
<span class="c1"># pySAP - Copyright (C) CEA, 2017 - 2018</span>
<span class="c1"># Distributed under the terms of the CeCILL-B license, as published by</span>
<span class="c1"># the CEA-CNRS-INRIA. Refer to the LICENSE file or to</span>
<span class="c1"># http://www.cecill.info/licences/Licence_CeCILL-B_V1-en.html</span>
<span class="c1"># for details.</span>
<span class="c1">##########################################################################</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">FISTA or CONDAT-VU MRI reconstruction.</span>
<span class="sd">&quot;&quot;&quot;</span>


<span class="c1"># System import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="c1"># Package import</span>
<span class="kn">from</span> <span class="nn">mri.numerics.reweight</span> <span class="kn">import</span> <span class="n">mReweight</span>
<span class="kn">from</span> <span class="nn">pysap.utils</span> <span class="kn">import</span> <span class="n">fista_logo</span>
<span class="kn">from</span> <span class="nn">pysap.utils</span> <span class="kn">import</span> <span class="n">condatvu_logo</span>
<span class="kn">from</span> <span class="nn">pysap.base.utils</span> <span class="kn">import</span> <span class="n">unflatten</span>

<span class="c1"># Third party import</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">modopt.math.stats</span> <span class="kn">import</span> <span class="n">sigma_mad</span>
<span class="kn">from</span> <span class="nn">modopt.opt.linear</span> <span class="kn">import</span> <span class="n">Identity</span>
<span class="kn">from</span> <span class="nn">modopt.opt.proximity</span> <span class="kn">import</span> <span class="n">Positivity</span>
<span class="kn">from</span> <span class="nn">modopt.opt.algorithms</span> <span class="kn">import</span> <span class="n">Condat</span><span class="p">,</span> <span class="n">ForwardBackward</span><span class="p">,</span> <span class="n">POGM</span>
<span class="kn">from</span> <span class="nn">modopt.opt.reweight</span> <span class="kn">import</span> <span class="n">cwbReweight</span>


<div class="viewcode-block" id="sparse_rec_fista"><a class="viewcode-back" href="../../../generated/mri.numerics.reconstruct.html#mri.numerics.reconstruct.sparse_rec_fista">[docs]</a><span class="k">def</span> <span class="nf">sparse_rec_fista</span><span class="p">(</span><span class="n">gradient_op</span><span class="p">,</span> <span class="n">linear_op</span><span class="p">,</span> <span class="n">prox_op</span><span class="p">,</span> <span class="n">cost_op</span><span class="p">,</span>
                     <span class="n">lambda_init</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">max_nb_of_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
                     <span class="n">metric_call_period</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{},</span>
                     <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">lambda_update_params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; The FISTA sparse reconstruction without reweightings.</span>

<span class="sd">    .. note:: At the moment, tested only with 2D data.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    gradient_op: instance of class GradBase</span>
<span class="sd">        the gradient operator.</span>
<span class="sd">    linear_op: instance of LinearBase</span>
<span class="sd">        the linear operator: seek the sparsity, ie. a wavelet transform.</span>
<span class="sd">    prox_op: instance of ProximityParent</span>
<span class="sd">        the proximal operator.</span>
<span class="sd">    cost_op: instance of costObj</span>
<span class="sd">        the cost function used to check for convergence during the</span>
<span class="sd">        optimization.</span>
<span class="sd">    lambda_init: float, (default 1.0)</span>
<span class="sd">        initial value for the FISTA step.</span>
<span class="sd">    max_nb_of_iter: int (optional, default 300)</span>
<span class="sd">        the maximum number of iterations in the Condat-Vu proximal-dual</span>
<span class="sd">        splitting algorithm.</span>
<span class="sd">    metric_call_period: int (default 5)</span>
<span class="sd">        the period on which the metrics are compute.</span>
<span class="sd">    metrics: dict (optional, default None)</span>
<span class="sd">        the list of desired convergence metrics: {&#39;metric_name&#39;:</span>
<span class="sd">        [@metric, metric_parameter]}. See modopt for the metrics API.</span>
<span class="sd">    verbose: int (optional, default 0)</span>
<span class="sd">        the verbosity level.</span>
<span class="sd">    lambda_update_params: dict,</span>
<span class="sd">        Parameters for the lambda update in FISTA mode</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    x_final: ndarray</span>
<span class="sd">        the estimated FISTA solution.</span>
<span class="sd">    costs: list of float</span>
<span class="sd">        the cost function values.</span>
<span class="sd">    metrics: dict</span>
<span class="sd">        the requested metrics values during the optimization.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">clock</span><span class="p">()</span>

    <span class="c1"># Define the initial primal and dual solutions</span>
    <span class="n">x_init</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">gradient_op</span><span class="o">.</span><span class="n">fourier_op</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">complex</span><span class="p">)</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">linear_op</span><span class="o">.</span><span class="n">op</span><span class="p">(</span><span class="n">x_init</span><span class="p">)</span>
    <span class="n">alpha</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="c1"># Welcome message</span>
    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">fista_logo</span><span class="p">())</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - mu: &quot;</span><span class="p">,</span> <span class="n">prox_op</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - lipschitz constant: &quot;</span><span class="p">,</span> <span class="n">gradient_op</span><span class="o">.</span><span class="n">spec_rad</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - data: &quot;</span><span class="p">,</span> <span class="n">gradient_op</span><span class="o">.</span><span class="n">fourier_op</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">linear_op</span><span class="p">,</span> <span class="s2">&quot;nb_scale&quot;</span><span class="p">):</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - wavelet: &quot;</span><span class="p">,</span> <span class="n">linear_op</span><span class="p">,</span> <span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="n">linear_op</span><span class="o">.</span><span class="n">nb_scale</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - max iterations: &quot;</span><span class="p">,</span> <span class="n">max_nb_of_iter</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - image variable shape: &quot;</span><span class="p">,</span> <span class="n">x_init</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - alpha variable shape: &quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">)</span>

    <span class="n">beta_param</span> <span class="o">=</span> <span class="n">gradient_op</span><span class="o">.</span><span class="n">inv_spec_rad</span>
    <span class="k">if</span> <span class="n">lambda_update_params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;restart_strategy&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;greedy&quot;</span><span class="p">:</span>
        <span class="n">lambda_update_params</span><span class="p">[</span><span class="s2">&quot;min_beta&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gradient_op</span><span class="o">.</span><span class="n">inv_spec_rad</span>
        <span class="c1"># this value is the recommended one by J. Liang in his article</span>
        <span class="c1"># when introducing greedy FISTA.</span>
        <span class="c1"># ref: https://arxiv.org/pdf/1807.04005.pdf</span>
        <span class="n">beta_param</span> <span class="o">*=</span> <span class="mf">1.3</span>

    <span class="c1"># Define the optimizer</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="n">ForwardBackward</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span>
        <span class="n">grad</span><span class="o">=</span><span class="n">gradient_op</span><span class="p">,</span>
        <span class="n">prox</span><span class="o">=</span><span class="n">prox_op</span><span class="p">,</span>
        <span class="n">cost</span><span class="o">=</span><span class="n">cost_op</span><span class="p">,</span>
        <span class="n">auto_iterate</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
        <span class="n">metric_call_period</span><span class="o">=</span><span class="n">metric_call_period</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span>
        <span class="n">linear</span><span class="o">=</span><span class="n">linear_op</span><span class="p">,</span>
        <span class="n">lambda_param</span><span class="o">=</span><span class="n">lambda_init</span><span class="p">,</span>
        <span class="n">beta_param</span><span class="o">=</span><span class="n">beta_param</span><span class="p">,</span>
        <span class="o">**</span><span class="n">lambda_update_params</span><span class="p">)</span>
    <span class="n">cost_op</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">_cost_func</span>

    <span class="c1"># Perform the reconstruction</span>
    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Starting optimization...&quot;</span><span class="p">)</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">iterate</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="n">max_nb_of_iter</span><span class="p">)</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">clock</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># cost_op.plot_cost()</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">cost_op</span><span class="p">,</span> <span class="s2">&quot;cost&quot;</span><span class="p">):</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - final iteration number: &quot;</span><span class="p">,</span> <span class="n">cost_op</span><span class="o">.</span><span class="n">_iteration</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - final log10 cost value: &quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">cost_op</span><span class="o">.</span><span class="n">cost</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - converged: &quot;</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">converge</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Done.&quot;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Execution time: &quot;</span><span class="p">,</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">,</span> <span class="s2">&quot; seconds&quot;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">)</span>
    <span class="n">x_final</span> <span class="o">=</span> <span class="n">linear_op</span><span class="o">.</span><span class="n">adj_op</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">x_final</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">cost_op</span><span class="p">,</span> <span class="s2">&quot;cost&quot;</span><span class="p">):</span>
        <span class="n">costs</span> <span class="o">=</span> <span class="n">cost_op</span><span class="o">.</span><span class="n">_cost_list</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">costs</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">return</span> <span class="n">x_final</span><span class="p">,</span> <span class="n">costs</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">metrics</span></div>


<div class="viewcode-block" id="sparse_rec_condatvu"><a class="viewcode-back" href="../../../generated/mri.numerics.reconstruct.html#mri.numerics.reconstruct.sparse_rec_condatvu">[docs]</a><span class="k">def</span> <span class="nf">sparse_rec_condatvu</span><span class="p">(</span><span class="n">gradient_op</span><span class="p">,</span> <span class="n">linear_op</span><span class="p">,</span> <span class="n">prox_dual_op</span><span class="p">,</span> <span class="n">cost_op</span><span class="p">,</span>
                        <span class="n">std_est</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">std_est_method</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">std_thr</span><span class="o">=</span><span class="mf">2.</span><span class="p">,</span>
                        <span class="n">tau</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">relaxation_factor</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                        <span class="n">nb_of_reweights</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_nb_of_iter</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span>
                        <span class="n">add_positivity</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">metric_call_period</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                        <span class="n">metrics</span><span class="o">=</span><span class="p">{},</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; The Condat-Vu sparse reconstruction with reweightings.</span>

<span class="sd">    .. note:: At the moment, tested only with 2D data.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    gradient_op: instance of class GradBase</span>
<span class="sd">        the gradient operator.</span>
<span class="sd">    linear_op: instance of LinearBase</span>
<span class="sd">        the linear operator: seek the sparsity, ie. a wavelet transform.</span>
<span class="sd">    prox_dual_op: instance of ProximityParent</span>
<span class="sd">        the proximal dual operator.</span>
<span class="sd">    cost_op: instance of costObj</span>
<span class="sd">        the cost function used to check for convergence during the</span>
<span class="sd">        optimization.</span>
<span class="sd">    std_est: float, default None</span>
<span class="sd">        the noise std estimate.</span>
<span class="sd">        If None use the MAD as a consistent estimator for the std.</span>
<span class="sd">    std_est_method: str, default None</span>
<span class="sd">        if the standard deviation is not set, estimate this parameter using</span>
<span class="sd">        the mad routine in the image (&#39;primal&#39;) or in the sparse wavelet</span>
<span class="sd">        decomposition (&#39;dual&#39;) domain.</span>
<span class="sd">    std_thr: float, default 2.</span>
<span class="sd">        use this treshold expressed as a number of sigma in the residual</span>
<span class="sd">        proximity operator during the thresholding.</span>
<span class="sd">    tau, sigma: float, default None</span>
<span class="sd">        parameters of the Condat-Vu proximal-dual splitting algorithm.</span>
<span class="sd">        If None estimates these parameters.</span>
<span class="sd">    relaxation_factor: float, default 0.5</span>
<span class="sd">        parameter of the Condat-Vu proximal-dual splitting algorithm.</span>
<span class="sd">        If 1, no relaxation.</span>
<span class="sd">    nb_of_reweights: int, default 1</span>
<span class="sd">        the number of reweightings.</span>
<span class="sd">    max_nb_of_iter: int, default 150</span>
<span class="sd">        the maximum number of iterations in the Condat-Vu proximal-dual</span>
<span class="sd">        splitting algorithm.</span>
<span class="sd">    add_positivity: bool, default False</span>
<span class="sd">        by setting this option, set the proximity operator to identity or</span>
<span class="sd">        positive.</span>
<span class="sd">    atol: float, default 1e-4</span>
<span class="sd">        tolerance threshold for convergence.</span>
<span class="sd">    metric_call_period: int (default 5)</span>
<span class="sd">        the period on which the metrics are compute.</span>
<span class="sd">    metrics: dict (optional, default None)</span>
<span class="sd">        the list of desired convergence metrics: {&#39;metric_name&#39;:</span>
<span class="sd">        [@metric, metric_parameter]}. See modopt for the metrics API.</span>
<span class="sd">    verbose: int, default 0</span>
<span class="sd">        the verbosity level.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    x_final: ndarray</span>
<span class="sd">        the estimated CONDAT-VU solution.</span>
<span class="sd">    costs: list of float</span>
<span class="sd">        the cost function values.</span>
<span class="sd">    metrics: dict</span>
<span class="sd">        the requested metrics values during the optimization.</span>
<span class="sd">    y_final: ndarrat</span>
<span class="sd">        the estimated dual CONDAT-VU solution</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Check inputs</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">clock</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">std_est_method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="s2">&quot;primal&quot;</span><span class="p">,</span> <span class="s2">&quot;dual&quot;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Unrecognize std estimation method &#39;{0}&#39;.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">std_est_method</span><span class="p">))</span>

    <span class="c1"># Define the initial primal and dual solutions</span>
    <span class="n">x_init</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">gradient_op</span><span class="o">.</span><span class="n">fourier_op</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">complex</span><span class="p">)</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">linear_op</span><span class="o">.</span><span class="n">op</span><span class="p">(</span><span class="n">x_init</span><span class="p">)</span>

    <span class="c1"># Define the weights used during the thresholding in the dual domain,</span>
    <span class="c1"># the reweighting strategy, and the prox dual operator</span>

    <span class="c1"># Case1: estimate the noise std in the image domain</span>
    <span class="k">if</span> <span class="n">std_est_method</span> <span class="o">==</span> <span class="s2">&quot;primal&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">std_est</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">std_est</span> <span class="o">=</span> <span class="n">sigma_mad</span><span class="p">(</span><span class="n">gradient_op</span><span class="o">.</span><span class="n">MtX</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
        <span class="n">weights</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">std_thr</span> <span class="o">*</span> <span class="n">std_est</span>
        <span class="n">reweight_op</span> <span class="o">=</span> <span class="n">cwbReweight</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
        <span class="n">prox_dual_op</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">reweight_op</span><span class="o">.</span><span class="n">weights</span>

    <span class="c1"># Case2: estimate the noise std in the sparse wavelet domain</span>
    <span class="k">elif</span> <span class="n">std_est_method</span> <span class="o">==</span> <span class="s2">&quot;dual&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">std_est</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">std_est</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">weights</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">std_thr</span> <span class="o">*</span> <span class="n">std_est</span>
        <span class="n">reweight_op</span> <span class="o">=</span> <span class="n">mReweight</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">linear_op</span><span class="p">,</span> <span class="n">thresh_factor</span><span class="o">=</span><span class="n">std_thr</span><span class="p">)</span>
        <span class="n">prox_dual_op</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">reweight_op</span><span class="o">.</span><span class="n">weights</span>

    <span class="c1"># Case3: manual regularization mode, no reweighting</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">reweight_op</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="n">nb_of_reweights</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Define the Condat Vu optimizer: define the tau and sigma in the</span>
    <span class="c1"># Condat-Vu proximal-dual splitting algorithm if not already provided.</span>
    <span class="c1"># Check also that the combination of values will lead to convergence.</span>
    <span class="n">norm</span> <span class="o">=</span> <span class="n">linear_op</span><span class="o">.</span><span class="n">l2norm</span><span class="p">(</span><span class="n">gradient_op</span><span class="o">.</span><span class="n">fourier_op</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">lipschitz_cst</span> <span class="o">=</span> <span class="n">gradient_op</span><span class="o">.</span><span class="n">spec_rad</span>
    <span class="k">if</span> <span class="n">sigma</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.5</span>
    <span class="k">if</span> <span class="n">tau</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="c1"># to avoid numerics troubles with the convergence bound</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="mf">1.0e-8</span>
        <span class="c1"># due to the convergence bound</span>
        <span class="n">tau</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">lipschitz_cst</span><span class="o">/</span><span class="mi">2</span> <span class="o">+</span> <span class="n">sigma</span> <span class="o">*</span> <span class="n">norm</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
    <span class="n">convergence_test</span> <span class="o">=</span> <span class="p">(</span>
        <span class="mf">1.0</span> <span class="o">/</span> <span class="n">tau</span> <span class="o">-</span> <span class="n">sigma</span> <span class="o">*</span> <span class="n">norm</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">&gt;=</span> <span class="n">lipschitz_cst</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">)</span>

    <span class="c1"># Define initial primal and dual solutions</span>
    <span class="n">primal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">gradient_op</span><span class="o">.</span><span class="n">fourier_op</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">complex</span><span class="p">)</span>
    <span class="n">dual</span> <span class="o">=</span> <span class="n">linear_op</span><span class="o">.</span><span class="n">op</span><span class="p">(</span><span class="n">primal</span><span class="p">)</span>
    <span class="n">dual</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="c1"># Welcome message</span>
    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">condatvu_logo</span><span class="p">())</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - mu: &quot;</span><span class="p">,</span> <span class="n">prox_dual_op</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - lipschitz constant: &quot;</span><span class="p">,</span> <span class="n">gradient_op</span><span class="o">.</span><span class="n">spec_rad</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - tau: &quot;</span><span class="p">,</span> <span class="n">tau</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - sigma: &quot;</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - rho: &quot;</span><span class="p">,</span> <span class="n">relaxation_factor</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - std: &quot;</span><span class="p">,</span> <span class="n">std_est</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - 1/tau - sigma||L||^2 &gt;= beta/2: &quot;</span><span class="p">,</span> <span class="n">convergence_test</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - data: &quot;</span><span class="p">,</span> <span class="n">gradient_op</span><span class="o">.</span><span class="n">fourier_op</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">linear_op</span><span class="p">,</span> <span class="s2">&quot;nb_scale&quot;</span><span class="p">):</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - wavelet: &quot;</span><span class="p">,</span> <span class="n">linear_op</span><span class="p">,</span> <span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="n">linear_op</span><span class="o">.</span><span class="n">nb_scale</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - max iterations: &quot;</span><span class="p">,</span> <span class="n">max_nb_of_iter</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - number of reweights: &quot;</span><span class="p">,</span> <span class="n">nb_of_reweights</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - primal variable shape: &quot;</span><span class="p">,</span> <span class="n">primal</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - dual variable shape: &quot;</span><span class="p">,</span> <span class="n">dual</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">)</span>

    <span class="c1"># Define the proximity operator</span>
    <span class="k">if</span> <span class="n">add_positivity</span><span class="p">:</span>
        <span class="n">prox_op</span> <span class="o">=</span> <span class="n">Positivity</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">prox_op</span> <span class="o">=</span> <span class="n">Identity</span><span class="p">()</span>

    <span class="c1"># Define the optimizer</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="n">Condat</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">primal</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">dual</span><span class="p">,</span>
        <span class="n">grad</span><span class="o">=</span><span class="n">gradient_op</span><span class="p">,</span>
        <span class="n">prox</span><span class="o">=</span><span class="n">prox_op</span><span class="p">,</span>
        <span class="n">prox_dual</span><span class="o">=</span><span class="n">prox_dual_op</span><span class="p">,</span>
        <span class="n">linear</span><span class="o">=</span><span class="n">linear_op</span><span class="p">,</span>
        <span class="n">cost</span><span class="o">=</span><span class="n">cost_op</span><span class="p">,</span>
        <span class="n">rho</span><span class="o">=</span><span class="n">relaxation_factor</span><span class="p">,</span>
        <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span>
        <span class="n">tau</span><span class="o">=</span><span class="n">tau</span><span class="p">,</span>
        <span class="n">rho_update</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
        <span class="n">sigma_update</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
        <span class="n">tau_update</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
        <span class="n">auto_iterate</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
        <span class="n">metric_call_period</span><span class="o">=</span><span class="n">metric_call_period</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">)</span>
    <span class="n">cost_op</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">_cost_func</span>

    <span class="c1"># Perform the first reconstruction</span>
    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Starting optimization...&quot;</span><span class="p">)</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">iterate</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="n">max_nb_of_iter</span><span class="p">)</span>

    <span class="c1"># Loop through the number of reweightings</span>
    <span class="k">for</span> <span class="n">reweight_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_of_reweights</span><span class="p">):</span>

        <span class="c1"># Generate the new weights following reweighting prescription</span>
        <span class="k">if</span> <span class="n">std_est_method</span> <span class="o">==</span> <span class="s2">&quot;primal&quot;</span><span class="p">:</span>
            <span class="n">reweight_op</span><span class="o">.</span><span class="n">reweight</span><span class="p">(</span><span class="n">linear_op</span><span class="o">.</span><span class="n">op</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">_x_new</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">std_est</span> <span class="o">=</span> <span class="n">reweight_op</span><span class="o">.</span><span class="n">reweight</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">_x_new</span><span class="p">)</span>

        <span class="c1"># Welcome message</span>
        <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - reweight: &quot;</span><span class="p">,</span> <span class="n">reweight_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - std: &quot;</span><span class="p">,</span> <span class="n">std_est</span><span class="p">)</span>

        <span class="c1"># Update the weights in the dual proximity operator</span>
        <span class="n">prox_dual_op</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">reweight_op</span><span class="o">.</span><span class="n">weights</span>

        <span class="c1"># Perform optimisation with new weights</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">iterate</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="n">max_nb_of_iter</span><span class="p">)</span>

    <span class="c1"># Goodbye message</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">clock</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">cost_op</span><span class="p">,</span> <span class="s2">&quot;cost&quot;</span><span class="p">):</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - final iteration number: &quot;</span><span class="p">,</span> <span class="n">cost_op</span><span class="o">.</span><span class="n">_iteration</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - final cost value: &quot;</span><span class="p">,</span> <span class="n">cost_op</span><span class="o">.</span><span class="n">cost</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - converged: &quot;</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">converge</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Done.&quot;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Execution time: &quot;</span><span class="p">,</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">,</span> <span class="s2">&quot; seconds&quot;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">)</span>

    <span class="c1"># Get the final solution</span>
    <span class="n">x_final</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">x_final</span>
    <span class="n">y_final</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">y_final</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">cost_op</span><span class="p">,</span> <span class="s2">&quot;cost&quot;</span><span class="p">):</span>
        <span class="n">costs</span> <span class="o">=</span> <span class="n">cost_op</span><span class="o">.</span><span class="n">_cost_list</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">costs</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">return</span> <span class="n">x_final</span><span class="p">,</span> <span class="n">costs</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">metrics</span><span class="p">,</span> <span class="n">y_final</span></div>


<div class="viewcode-block" id="sparse_rec_pogm"><a class="viewcode-back" href="../../../generated/mri.numerics.reconstruct.html#mri.numerics.reconstruct.sparse_rec_pogm">[docs]</a><span class="k">def</span> <span class="nf">sparse_rec_pogm</span><span class="p">(</span><span class="n">gradient_op</span><span class="p">,</span> <span class="n">linear_op</span><span class="p">,</span> <span class="n">prox_op</span><span class="p">,</span> <span class="n">cost_op</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                    <span class="n">max_nb_of_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">metric_call_period</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">sigma_bar</span><span class="o">=</span><span class="mf">0.96</span><span class="p">,</span>
                    <span class="n">metrics</span><span class="o">=</span><span class="p">{},</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Perform sparse reconstruction using the POGM algorithm.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    gradient_op: instance of class GradBase</span>
<span class="sd">        the gradient operator.</span>
<span class="sd">    linear_op: instance of LinearBase</span>
<span class="sd">        the linear operator: seek the sparsity, ie. a wavelet transform.</span>
<span class="sd">    prox_op: instance of ProximityParent</span>
<span class="sd">        the proximal operator.</span>
<span class="sd">    cost_op: instance of costObj, (default None)</span>
<span class="sd">        the cost function used to check for convergence during the</span>
<span class="sd">        optimization.</span>
<span class="sd">    lambda_init: float, (default 1.0)</span>
<span class="sd">        initial value for the FISTA step.</span>
<span class="sd">    max_nb_of_iter: int (optional, default 300)</span>
<span class="sd">        the maximum number of iterations in the POGM algorithm.</span>
<span class="sd">    metric_call_period: int (default 5)</span>
<span class="sd">        the period on which the metrics are computed.</span>
<span class="sd">    metrics: dict (optional, default None)</span>
<span class="sd">        the list of desired convergence metrics: {&#39;metric_name&#39;:</span>
<span class="sd">        [@metric, metric_parameter]}. See modopt for the metrics API.</span>
<span class="sd">    verbose: int (optional, default 0)</span>
<span class="sd">        the verbosity level.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    x_final: ndarray</span>
<span class="sd">        the estimated POGM solution.</span>
<span class="sd">    costs: list of float</span>
<span class="sd">        the cost function values.</span>
<span class="sd">    metrics: dict</span>
<span class="sd">        the requested metrics values during the optimization.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">clock</span><span class="p">()</span>

    <span class="c1"># Define the initial values</span>
    <span class="n">im_shape</span> <span class="o">=</span> <span class="n">gradient_op</span><span class="o">.</span><span class="n">fourier_op</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">zeros_right_shape</span> <span class="o">=</span> <span class="n">linear_op</span><span class="o">.</span><span class="n">op</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">im_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;complex128&#39;</span><span class="p">))</span>

    <span class="c1"># Welcome message</span>
    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># TODO: think of logo for POGM</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - mu: &quot;</span><span class="p">,</span> <span class="n">prox_op</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - lipschitz constant: &quot;</span><span class="p">,</span> <span class="n">gradient_op</span><span class="o">.</span><span class="n">spec_rad</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - data: &quot;</span><span class="p">,</span> <span class="n">gradient_op</span><span class="o">.</span><span class="n">fourier_op</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">linear_op</span><span class="p">,</span> <span class="s2">&quot;nb_scale&quot;</span><span class="p">):</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - wavelet: &quot;</span><span class="p">,</span> <span class="n">linear_op</span><span class="p">,</span> <span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="n">linear_op</span><span class="o">.</span><span class="n">nb_scale</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - max iterations: &quot;</span><span class="p">,</span> <span class="n">max_nb_of_iter</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - image variable shape: &quot;</span><span class="p">,</span> <span class="n">im_shape</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">)</span>

    <span class="c1"># Hyper-parameters</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">gradient_op</span><span class="o">.</span><span class="n">inv_spec_rad</span>

    <span class="n">opt</span> <span class="o">=</span> <span class="n">POGM</span><span class="p">(</span>
        <span class="n">u</span><span class="o">=</span><span class="n">zeros_right_shape</span><span class="p">,</span>
        <span class="n">x</span><span class="o">=</span><span class="n">zeros_right_shape</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">zeros_right_shape</span><span class="p">,</span>
        <span class="n">z</span><span class="o">=</span><span class="n">zeros_right_shape</span><span class="p">,</span>
        <span class="n">grad</span><span class="o">=</span><span class="n">gradient_op</span><span class="p">,</span>
        <span class="n">prox</span><span class="o">=</span><span class="n">prox_op</span><span class="p">,</span>
        <span class="n">cost</span><span class="o">=</span><span class="n">cost_op</span><span class="p">,</span>
        <span class="n">beta_param</span><span class="o">=</span><span class="n">beta</span><span class="p">,</span>
        <span class="n">sigma_bar</span><span class="o">=</span><span class="n">sigma_bar</span><span class="p">,</span>
        <span class="n">metric_call_period</span><span class="o">=</span><span class="n">metric_call_period</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span>
        <span class="n">auto_iterate</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Perform the reconstruction</span>
    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Starting optimization...&quot;</span><span class="p">)</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">iterate</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="n">max_nb_of_iter</span><span class="p">)</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">clock</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># cost_op.plot_cost()</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">cost_op</span><span class="p">,</span> <span class="s2">&quot;cost&quot;</span><span class="p">):</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - final iteration number: &quot;</span><span class="p">,</span> <span class="n">cost_op</span><span class="o">.</span><span class="n">_iteration</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - final log10 cost value: &quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">cost_op</span><span class="o">.</span><span class="n">cost</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; - converged: &quot;</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">converge</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Done.&quot;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Execution time: &quot;</span><span class="p">,</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">,</span> <span class="s2">&quot; seconds&quot;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">)</span>
    <span class="n">x_final</span> <span class="o">=</span> <span class="n">linear_op</span><span class="o">.</span><span class="n">adj_op</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">x_final</span><span class="p">)</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">metrics</span>

    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">cost_op</span><span class="p">,</span> <span class="s2">&quot;cost&quot;</span><span class="p">):</span>
        <span class="n">costs</span> <span class="o">=</span> <span class="n">cost_op</span><span class="o">.</span><span class="n">_cost_list</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">costs</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">return</span> <span class="n">x_final</span><span class="p">,</span> <span class="n">costs</span><span class="p">,</span> <span class="n">metrics</span></div>
</pre></div>

          </div>
        </div>
      </div>

    <div class="clearer">
    </div>
  </div>
  
</div>

<div class="footer">
    &copy; 2019, 
Antoine Grigis &lt;antoine.grigis@cea.fr&gt;
Samuel Farrens &lt;samuel.farrens@cea.fr&gt;
Jean-Luc Starck &lt;jl.stark@cea.fr&gt;
Philippe Ciuciu &lt;philippe.ciuciu@cea.fr&gt;
 &lt;XXX&gt;.
</div>
  </body>
</html>